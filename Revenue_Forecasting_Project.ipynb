{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Problem statement\n",
        "\n",
        "As part of a trading team that makes investments based on [Fundamental Analysis](https://https://en.wikipedia.org/wiki/Fundamental_analysis).\n",
        "\n",
        "Your purpose is to produce revenue growth forecasts for firms in a given industry based on financial charateristics of these firms and relevant economic data. Your forecasts are then used in a larger decision making system.\n",
        "\n",
        "You have access to a dataset of 15,000 observations. Each observation $(X_i, y_i)$ consists of 4,000 economic and financial indicators that could presumably forecast revenue growth for the next quarter, and the corresponding revenue growth for that observation ($y_i$).\n",
        "\n",
        "The corresponding data set is given below:\n",
        "\n",
        "X.npy: https://drive.google.com/file/d/1SbC0xE1PPK0gL6J2yolIaQ07eoNVk2bM\n",
        "\n",
        "\n",
        "y.py: https://drive.google.com/file/d/1HxnGlU_epSaiDppRCzkZAX8AJIkV0xvS\n",
        "\n",
        "\n",
        "# Task\n",
        "Construct a linear model to forecast revenue growth based on the data you have. You model will be evaluated based on the mean squared error between your predictions and the labels evaluated at a test set. The test set comes from the same distribution as the training set and the evaluation set.\n",
        "\n"
      ],
      "metadata": {
        "id": "W14vyBYt8eE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "file_id_X = '1SbC0xE1PPK0gL6J2yolIaQ07eoNVk2bM'\n",
        "\n",
        "gdown.download(f'https://drive.google.com/uc?id={file_id_X}', 'X.npy', quiet=False)\n",
        "X = np.load('X.npy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4BVPu2nouxE",
        "outputId": "a7daf40b-45e7-4448-9999-7ce3c1eda716"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1SbC0xE1PPK0gL6J2yolIaQ07eoNVk2bM\n",
            "From (redirected): https://drive.google.com/uc?id=1SbC0xE1PPK0gL6J2yolIaQ07eoNVk2bM&confirm=t&uuid=85699aa0-38a6-4a0d-9412-07caa9f78343\n",
            "To: /content/X.npy\n",
            "100%|██████████| 240M/240M [00:03<00:00, 61.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.load('X.npy')\n",
        "print('X shape:', X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyYW9hoEo6at",
        "outputId": "0df8aeba-5092-466e-c260-311c87b4416c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (15000, 4000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_id_y = '1HxnGlU_epSaiDppRCzkZAX8AJIkV0xvS'\n",
        "\n",
        "gdown.download(f'https://drive.google.com/uc?id={file_id_y}', 'y.py', quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "cV2x-tPQo8dU",
        "outputId": "a323ff27-a98f-4258-8527-f78d9a28f370"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1HxnGlU_epSaiDppRCzkZAX8AJIkV0xvS\n",
            "To: /content/y.py\n",
            "100%|██████████| 60.1k/60.1k [00:00<00:00, 43.7MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'y.py'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.load('y.py')\n",
        "print('y shape:', y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUTK1HFNo_C9",
        "outputId": "93b1363a-2be1-4a84-b268-c6d4e46f1bfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y shape: (15000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "that returns the predictions of you model for a new dataset X.\n"
      ],
      "metadata": {
        "id": "0HYsGt6WYtLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax.numpy as jnp\n",
        "import jax\n",
        "import optax\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(100)\n",
        "\n",
        "\n",
        "@jax.jit\n",
        "def mse(y_true, y_predict):\n",
        "    return jnp.mean((y_true - y_predict) ** 2)\n",
        "\n",
        "\n",
        "@jax.jit\n",
        "def dL(theta, X_tmp, y_tmp):\n",
        "    def loss_fn(theta):\n",
        "        y_predict = X_tmp @ theta\n",
        "        return mse(y_tmp, y_predict)\n",
        "\n",
        "    grad = jax.grad(loss_fn)(theta)\n",
        "\n",
        "    return grad\n",
        "\n",
        "def sample(X_tmp, y_tmp):\n",
        "    N = len(X_tmp)\n",
        "    batch_size = int(jnp.sqrt(N))\n",
        "    idx = np.random.choice(N, batch_size)\n",
        "    return X_tmp[idx], y_tmp[idx]\n",
        "\n",
        "@jax.jit\n",
        "def update_fn(theta, opt_state, X_tmp, y_tmp, alpha, beta, beta2):\n",
        "    grad = dL(theta, X_tmp, y_tmp)\n",
        "    optmizer = optax.adam(alpha, beta, beta2)\n",
        "    updates, opt_state = optmizer.update(grad, opt_state)\n",
        "    theta = optax.apply_updates(theta, updates)\n",
        "    return theta, opt_state\n",
        "\n",
        "def optimized_theta(X_train, y_train, X_val, y_val):\n",
        "    n_model = 20 # Optimizing 20 different models at the same time\n",
        "    max_iterations=50000\n",
        "    theta = jnp.zeros(len(X_train[0]))\n",
        "    alpha_list = [0.1, 0.05, 0.01, 1e-3, 1e-4, 1e-6]\n",
        "    beta_list = [0.1, 0.2, 0.5, 0.9]\n",
        "    beta2_list = [0.1, 0.2, 0.5, 0.9]\n",
        "    alpha_vec = np.random.choice(alpha_list, n_model)\n",
        "    beta_vec = np.random.choice(beta_list, n_model)\n",
        "    beta2_vec = np.random.choice(beta2_list, n_model)\n",
        "    hyperparams = dict({'alpha': alpha_vec, 'beta': beta_vec, 'beta2': beta2_vec})\n",
        "\n",
        "    @jax.jit\n",
        "    def stack(theta):\n",
        "        return jnp.stack([theta] * n_model)\n",
        "\n",
        "    optmizer = optax.adam(alpha_list[1], beta_vec[1], beta2_vec[1])\n",
        "    opt_state = optmizer.init(theta)\n",
        "    theta = stack(theta)\n",
        "    opt_state = jax.tree.map(stack, opt_state)\n",
        "    update = jax.jit(jax.vmap(update_fn, in_axes=(0, 0, None, None, 0, 0, 0)))\n",
        "\n",
        "\n",
        "    for iteration in range(max_iterations+1):\n",
        "        if iteration% 2000 ==0:\n",
        "            print(f'Iterated {iteration} times')\n",
        "        Xi, yi = sample(X_train, y_train)\n",
        "        theta, opt_state = update(theta, opt_state, Xi, yi, alpha_vec, beta_vec, beta2_vec)\n",
        "\n",
        "    # calculate all MSEs，find best theta\n",
        "    mse_values = []\n",
        "    for i in range(n_model):\n",
        "        y_pred = X_val @ theta[i]\n",
        "        mse_value = mse(y_val, y_pred)\n",
        "        mse_values.append(mse_value)\n",
        "\n",
        "    # choose Best MSE's theta\n",
        "    index = jnp.argmin(jnp.array(mse_values))\n",
        "    best_theta = theta[index]\n",
        "    mse_values[index]\n",
        "    print(f\"Best model index: {index} \\nBest training MSE: {mse(y_train, X_train @ best_theta)} \\nBest validating MSE:{mse_values[index]}\")\n",
        "\n",
        "    return best_theta\n",
        "\n",
        "def f(X):\n",
        "    theta = optimized_theta(X_train, y_train, X_val, y_val)\n",
        "    prediction = X @ theta\n",
        "    np.save('theta.npy', theta)\n",
        "    return prediction\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "data = jnp.load('./X.npy') # loading features and targets\n",
        "y = jnp.load('./y.py')\n",
        "n = len(data)\n",
        "train_size = int(0.6 * len(data))\n",
        "val_size = int(0.2 * n)\n",
        "test_size = n - train_size - val_size\n",
        "\n",
        "indices = np.random.permutation(len(data))\n",
        "X_train = data[indices[:train_size]]\n",
        "X_val = data[indices[train_size:train_size + val_size]]\n",
        "X_test = data[indices[train_size + val_size:]]\n",
        "\n",
        "y_train = y[indices[:train_size]]\n",
        "y_val = y[indices[train_size:train_size + val_size]]\n",
        "y_test = y[indices[train_size + val_size:]]\n",
        "prediction = f(X_test)\n",
        "print('Testing MSE: ',mse(prediction, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2h30jx5DJQ6",
        "outputId": "67a79562-5860-4021-e5c3-dd04b42a0fdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iterated 0 times\n",
            "Iterated 2000 times\n",
            "Iterated 4000 times\n",
            "Iterated 6000 times\n",
            "Iterated 8000 times\n",
            "Iterated 10000 times\n",
            "Iterated 12000 times\n",
            "Iterated 14000 times\n",
            "Iterated 16000 times\n",
            "Iterated 18000 times\n",
            "Iterated 20000 times\n",
            "Iterated 22000 times\n",
            "Iterated 24000 times\n",
            "Iterated 26000 times\n",
            "Iterated 28000 times\n",
            "Iterated 30000 times\n",
            "Iterated 32000 times\n",
            "Iterated 34000 times\n",
            "Iterated 36000 times\n",
            "Iterated 38000 times\n",
            "Iterated 40000 times\n",
            "Iterated 42000 times\n",
            "Iterated 44000 times\n",
            "Iterated 46000 times\n",
            "Iterated 48000 times\n",
            "Iterated 50000 times\n",
            "Best model index: 3 \n",
            "Best training MSE: 0.016544833779335022 \n",
            "Best validating MSE:0.019632613286376\n",
            "Testing MSE:  0.02027469\n"
          ]
        }
      ]
    }
  ]
}